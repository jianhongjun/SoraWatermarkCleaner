"""
Cloudflare R2 æ–‡ä»¶ä¸Šä¼ å·¥å…·
æ”¯æŒå•æ–‡ä»¶ä¸Šä¼ ã€æ‰¹é‡ä¸Šä¼ ã€è¿›åº¦æ˜¾ç¤ºç­‰åŠŸèƒ½
"""

import os
import time
import hashlib
from typing import Optional, Dict, Any, List, Callable
from pathlib import Path
import mimetypes
from urllib.parse import urlparse

import boto3
from botocore.exceptions import ClientError, NoCredentialsError
from botocore.config import Config
import requests
from tqdm import tqdm


class CloudflareR2Uploader:
    """Cloudflare R2 æ–‡ä»¶ä¸Šä¼ å™¨"""
    
    def __init__(
        self,
        account_id: str,
        access_key_id: str,
        secret_access_key: str,
        bucket_name: str,
        region: str = "auto",
        endpoint_url: Optional[str] = None
    ):
        """
        åˆå§‹åŒ– R2 ä¸Šä¼ å™¨
        
        Args:
            account_id: Cloudflare è´¦æˆ· ID
            access_key_id: R2 API Token çš„ Access Key ID
            secret_access_key: R2 API Token çš„ Secret Access Key
            bucket_name: R2 å­˜å‚¨æ¡¶åç§°
            region: åŒºåŸŸï¼Œé€šå¸¸ä¸º "auto"
            endpoint_url: è‡ªå®šä¹‰ç«¯ç‚¹ URL
        """
        self.account_id = account_id
        self.bucket_name = bucket_name
        self.region = region
        
        # æ„å»ºç«¯ç‚¹ URL
        if endpoint_url is None:
            endpoint_url = f"https://{account_id}.r2.cloudflarestorage.com"
        
        # é…ç½® boto3 å®¢æˆ·ç«¯
        self.s3_client = boto3.client(
            's3',
            endpoint_url=endpoint_url,
            aws_access_key_id=access_key_id,
            aws_secret_access_key=secret_access_key,
            region_name=region,
            config=Config(
                signature_version='s3v4',
                s3={
                    'addressing_style': 'path'
                }
            )
        )
        
        # éªŒè¯è¿æ¥
        self._verify_connection()
    
    def _verify_connection(self) -> None:
        """éªŒè¯ R2 è¿æ¥"""
        try:
            self.s3_client.head_bucket(Bucket=self.bucket_name)
            print(f"âœ… æˆåŠŸè¿æ¥åˆ° R2 å­˜å‚¨æ¡¶: {self.bucket_name}")
        except ClientError as e:
            error_code = e.response['Error']['Code']
            if error_code == '404':
                raise Exception(f"å­˜å‚¨æ¡¶ '{self.bucket_name}' ä¸å­˜åœ¨")
            elif error_code == '403':
                raise Exception(f"æ²¡æœ‰è®¿é—®å­˜å‚¨æ¡¶ '{self.bucket_name}' çš„æƒé™")
            else:
                raise Exception(f"è¿æ¥ R2 å¤±è´¥: {e}")
        except NoCredentialsError:
            raise Exception("R2 å‡­æ®æ— æ•ˆæˆ–ç¼ºå¤±")
    
    def _get_content_type(self, file_path: str) -> str:
        """è·å–æ–‡ä»¶ MIME ç±»å‹"""
        content_type, _ = mimetypes.guess_type(file_path)
        return content_type or 'application/octet-stream'
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶ MD5 å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _create_progress_callback(self, file_size: int, filename: str) -> Callable:
        """åˆ›å»ºä¸Šä¼ è¿›åº¦å›è°ƒå‡½æ•°"""
        progress_bar = tqdm(
            total=file_size,
            unit='B',
            unit_scale=True,
            desc=f"ä¸Šä¼  {filename}",
            ncols=80
        )
        
        def callback(bytes_transferred):
            progress_bar.update(bytes_transferred)
        
        return callback, progress_bar
    
    def upload_file(
        self,
        local_file_path: str,
        remote_key: Optional[str] = None,
        content_type: Optional[str] = None,
        metadata: Optional[Dict[str, str]] = None,
        show_progress: bool = True,
        overwrite: bool = True
    ) -> Dict[str, Any]:
        """
        ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ° R2
        
        Args:
            local_file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            remote_key: è¿œç¨‹æ–‡ä»¶é”®åï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨æ–‡ä»¶å
            content_type: æ–‡ä»¶ MIME ç±»å‹ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨æ£€æµ‹
            metadata: æ–‡ä»¶å…ƒæ•°æ®
            show_progress: æ˜¯å¦æ˜¾ç¤ºä¸Šä¼ è¿›åº¦
            overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            
        Returns:
            ä¸Šä¼ ç»“æœä¿¡æ¯
        """
        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(local_file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_path = Path(local_file_path)
        file_size = file_path.stat().st_size
        
        # è®¾ç½®è¿œç¨‹é”®å
        if remote_key is None:
            remote_key = file_path.name
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if not overwrite:
            try:
                self.s3_client.head_object(Bucket=self.bucket_name, Key=remote_key)
                raise FileExistsError(f"æ–‡ä»¶å·²å­˜åœ¨: {remote_key}")
            except ClientError as e:
                if e.response['Error']['Code'] != '404':
                    raise
        
        # è®¾ç½®å†…å®¹ç±»å‹
        if content_type is None:
            content_type = self._get_content_type(local_file_path)
        
        # å‡†å¤‡ä¸Šä¼ å‚æ•°
        upload_kwargs = {
            'Bucket': self.bucket_name,
            'Key': remote_key,
            'ContentType': content_type
        }
        
        # æ·»åŠ å…ƒæ•°æ®
        if metadata:
            upload_kwargs['Metadata'] = metadata
        
        # æ·»åŠ æ–‡ä»¶å“ˆå¸Œ
        file_hash = self._calculate_file_hash(local_file_path)
        upload_kwargs['Metadata'] = upload_kwargs.get('Metadata', {})
        upload_kwargs['Metadata']['file-hash'] = file_hash
        
        try:
            if show_progress and file_size > 1024 * 1024:  # å¤§äº 1MB æ˜¾ç¤ºè¿›åº¦
                callback, progress_bar = self._create_progress_callback(file_size, file_path.name)
                
                self.s3_client.upload_file(
                    local_file_path,
                    self.bucket_name,
                    remote_key,
                    ExtraArgs={
                        'ContentType': content_type,
                        'Metadata': upload_kwargs['Metadata']
                    },
                    Callback=callback
                )
                progress_bar.close()
            else:
                self.s3_client.upload_file(
                    local_file_path,
                    self.bucket_name,
                    remote_key,
                    ExtraArgs={
                        'ContentType': content_type,
                        'Metadata': upload_kwargs['Metadata']
                    }
                )
            
            # è·å–ä¸Šä¼ åçš„æ–‡ä»¶ä¿¡æ¯
            response = self.s3_client.head_object(Bucket=self.bucket_name, Key=remote_key)
            
            result = {
                'success': True,
                'local_path': local_file_path,
                'remote_key': remote_key,
                'file_size': file_size,
                'content_type': content_type,
                'etag': response.get('ETag', '').strip('"'),
                'last_modified': response.get('LastModified'),
                'metadata': response.get('Metadata', {}),
                'url': f"https://{self.bucket_name}.{self.account_id}.r2.cloudflarestorage.com/{remote_key}"
            }
            
            print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {remote_key}")
            return result
            
        except ClientError as e:
            error_msg = f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'local_path': local_file_path,
                'remote_key': remote_key
            }
    
    def upload_multipart(
        self,
        local_file_path: str,
        remote_key: Optional[str] = None,
        part_size: int = 5 * 1024 * 1024,  # 5MB
        content_type: Optional[str] = None,
        metadata: Optional[Dict[str, str]] = None,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨åˆ†ç‰‡ä¸Šä¼ å¤§æ–‡ä»¶
        
        Args:
            local_file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            remote_key: è¿œç¨‹æ–‡ä»¶é”®å
            part_size: åˆ†ç‰‡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            content_type: æ–‡ä»¶ MIME ç±»å‹
            metadata: æ–‡ä»¶å…ƒæ•°æ®
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            ä¸Šä¼ ç»“æœä¿¡æ¯
        """
        if not os.path.exists(local_file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")
        
        file_path = Path(local_file_path)
        file_size = file_path.stat().st_size
        
        if remote_key is None:
            remote_key = file_path.name
        
        if content_type is None:
            content_type = self._get_content_type(local_file_path)
        
        # å‡†å¤‡ä¸Šä¼ å‚æ•°
        upload_kwargs = {
            'Bucket': self.bucket_name,
            'Key': remote_key,
            'ContentType': content_type
        }
        
        if metadata:
            upload_kwargs['Metadata'] = metadata
        
        try:
            # åˆ›å»ºåˆ†ç‰‡ä¸Šä¼ 
            response = self.s3_client.create_multipart_upload(**upload_kwargs)
            upload_id = response['UploadId']
            
            # è®¡ç®—åˆ†ç‰‡æ•°é‡
            num_parts = (file_size + part_size - 1) // part_size
            
            parts = []
            progress_bar = None
            
            if show_progress:
                progress_bar = tqdm(
                    total=file_size,
                    unit='B',
                    unit_scale=True,
                    desc=f"åˆ†ç‰‡ä¸Šä¼  {file_path.name}",
                    ncols=80
                )
            
            try:
                with open(local_file_path, 'rb') as file:
                    for part_num in range(1, num_parts + 1):
                        # è¯»å–åˆ†ç‰‡æ•°æ®
                        chunk = file.read(part_size)
                        
                        # ä¸Šä¼ åˆ†ç‰‡
                        part_response = self.s3_client.upload_part(
                            Bucket=self.bucket_name,
                            Key=remote_key,
                            PartNumber=part_num,
                            UploadId=upload_id,
                            Body=chunk
                        )
                        
                        parts.append({
                            'ETag': part_response['ETag'],
                            'PartNumber': part_num
                        })
                        
                        if progress_bar:
                            progress_bar.update(len(chunk))
                
                # å®Œæˆåˆ†ç‰‡ä¸Šä¼ 
                self.s3_client.complete_multipart_upload(
                    Bucket=self.bucket_name,
                    Key=remote_key,
                    UploadId=upload_id,
                    MultipartUpload={'Parts': parts}
                )
                
                if progress_bar:
                    progress_bar.close()
                
                result = {
                    'success': True,
                    'local_path': local_file_path,
                    'remote_key': remote_key,
                    'file_size': file_size,
                    'content_type': content_type,
                    'upload_type': 'multipart',
                    'parts_count': num_parts,
                    'url': f"https://{self.bucket_name}.{self.account_id}.r2.cloudflarestorage.com/{remote_key}"
                }
                
                print(f"âœ… åˆ†ç‰‡ä¸Šä¼ æˆåŠŸ: {remote_key} ({num_parts} ä¸ªåˆ†ç‰‡)")
                return result
                
            except Exception as e:
                # å–æ¶ˆåˆ†ç‰‡ä¸Šä¼ 
                self.s3_client.abort_multipart_upload(
                    Bucket=self.bucket_name,
                    Key=remote_key,
                    UploadId=upload_id
                )
                raise e
                
        except ClientError as e:
            error_msg = f"åˆ†ç‰‡ä¸Šä¼ å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            return {
                'success': False,
                'error': error_msg,
                'local_path': local_file_path,
                'remote_key': remote_key
            }
    
    def upload_directory(
        self,
        local_dir_path: str,
        remote_prefix: str = "",
        include_patterns: Optional[List[str]] = None,
        exclude_patterns: Optional[List[str]] = None,
        show_progress: bool = True
    ) -> Dict[str, Any]:
        """
        ä¸Šä¼ æ•´ä¸ªç›®å½•
        
        Args:
            local_dir_path: æœ¬åœ°ç›®å½•è·¯å¾„
            remote_prefix: è¿œç¨‹å‰ç¼€
            include_patterns: åŒ…å«çš„æ–‡ä»¶æ¨¡å¼
            exclude_patterns: æ’é™¤çš„æ–‡ä»¶æ¨¡å¼
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            ä¸Šä¼ ç»“æœç»Ÿè®¡
        """
        if not os.path.isdir(local_dir_path):
            raise NotADirectoryError(f"ç›®å½•ä¸å­˜åœ¨: {local_dir_path}")
        
        dir_path = Path(local_dir_path)
        results = {
            'success': 0,
            'failed': 0,
            'total': 0,
            'files': []
        }
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶
        all_files = []
        for file_path in dir_path.rglob('*'):
            if file_path.is_file():
                # æ£€æŸ¥åŒ…å«æ¨¡å¼
                if include_patterns:
                    if not any(file_path.match(pattern) for pattern in include_patterns):
                        continue
                
                # æ£€æŸ¥æ’é™¤æ¨¡å¼
                if exclude_patterns:
                    if any(file_path.match(pattern) for pattern in exclude_patterns):
                        continue
                
                all_files.append(file_path)
        
        results['total'] = len(all_files)
        
        if show_progress:
            file_progress = tqdm(all_files, desc="ä¸Šä¼ ç›®å½•", ncols=80)
        else:
            file_progress = all_files
        
        for file_path in file_progress:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            relative_path = file_path.relative_to(dir_path)
            remote_key = f"{remote_prefix}/{relative_path}".lstrip('/')
            
            try:
                result = self.upload_file(
                    str(file_path),
                    remote_key,
                    show_progress=False
                )
                
                if result['success']:
                    results['success'] += 1
                else:
                    results['failed'] += 1
                
                results['files'].append(result)
                
            except Exception as e:
                results['failed'] += 1
                results['files'].append({
                    'success': False,
                    'error': str(e),
                    'local_path': str(file_path),
                    'remote_key': remote_key
                })
        
        print(f"ğŸ“ ç›®å½•ä¸Šä¼ å®Œæˆ: æˆåŠŸ {results['success']}/{results['total']} ä¸ªæ–‡ä»¶")
        return results
    
    def get_file_url(self, remote_key: str, expires_in: int = 3600) -> str:
        """
        è·å–æ–‡ä»¶çš„é¢„ç­¾å URL
        
        Args:
            remote_key: è¿œç¨‹æ–‡ä»¶é”®å
            expires_in: URL è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            é¢„ç­¾å URL
        """
        try:
            url = self.s3_client.generate_presigned_url(
                'get_object',
                Params={'Bucket': self.bucket_name, 'Key': remote_key},
                ExpiresIn=expires_in
            )
            return url
        except ClientError as e:
            raise Exception(f"ç”Ÿæˆé¢„ç­¾å URL å¤±è´¥: {e}")
    
    def delete_file(self, remote_key: str) -> bool:
        """
        åˆ é™¤æ–‡ä»¶
        
        Args:
            remote_key: è¿œç¨‹æ–‡ä»¶é”®å
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            self.s3_client.delete_object(Bucket=self.bucket_name, Key=remote_key)
            print(f"ğŸ—‘ï¸ æ–‡ä»¶åˆ é™¤æˆåŠŸ: {remote_key}")
            return True
        except ClientError as e:
            print(f"âŒ æ–‡ä»¶åˆ é™¤å¤±è´¥: {e}")
            return False
    
    def list_files(self, prefix: str = "", max_keys: int = 1000) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ–‡ä»¶
        
        Args:
            prefix: æ–‡ä»¶å‰ç¼€
            max_keys: æœ€å¤§è¿”å›æ•°é‡
            
        Returns:
            æ–‡ä»¶åˆ—è¡¨
        """
        try:
            response = self.s3_client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix=prefix,
                MaxKeys=max_keys
            )
            
            files = []
            for obj in response.get('Contents', []):
                files.append({
                    'key': obj['Key'],
                    'size': obj['Size'],
                    'last_modified': obj['LastModified'],
                    'etag': obj['ETag'].strip('"'),
                    'url': f"https://{self.bucket_name}.{self.account_id}.r2.cloudflarestorage.com/{obj['Key']}"
                })
            
            return files
        except ClientError as e:
            raise Exception(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}")
"""token YQCXJt27x1jIfEKlRGTrs733jZtONayZK080wnH7 """

def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    # é…ç½®ä¿¡æ¯ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…é…ç½®ï¼‰
    config = {
        'account_id': 'ff4dc1637dea73f687c64ec9d2f17009',
        'access_key_id': 'b60ebd3d363f4a31d5b836f0d888f308',
        'secret_access_key': 'dcdef3ae6d52b7a8442a9fbc53cccc0f56c227407fda25ee86534ded8e3991de',
        'bucket_name': 'sora'
    }
    
    try:
        # åˆ›å»ºä¸Šä¼ å™¨
        uploader = CloudflareR2Uploader(**config)
        
        # ç¤ºä¾‹ 1: ä¸Šä¼ å•ä¸ªæ–‡ä»¶
        # print("=== ä¸Šä¼ å•ä¸ªæ–‡ä»¶ ===")
        # result = uploader.upload_file(
        #     'resources/puppies.mp4',
        #     'uploads/puppies.mp4',
        #     metadata={'author': 'python_script', 'version': '1.0'}
        # )
        # print(f"ä¸Šä¼ ç»“æœ: {result}")
        
        # # ç¤ºä¾‹ 2: åˆ†ç‰‡ä¸Šä¼ å¤§æ–‡ä»¶
        print("\n=== åˆ†ç‰‡ä¸Šä¼ å¤§æ–‡ä»¶ ===")
        # result = uploader.upload_multipart(
        #     '../../resources/puppies.mp4',
        #     'uploads/puppies.mp4',
        #     part_size=10 * 1024 * 1024  # 10MB åˆ†ç‰‡
        # )
        # print(f"åˆ†ç‰‡ä¸Šä¼ ç»“æœ: {result}")
        #
        # # ç¤ºä¾‹ 3: ä¸Šä¼ ç›®å½•
        # print("\n=== ä¸Šä¼ ç›®å½• ===")
        # result = uploader.upload_directory(
        #     './uploads',
        #     'backup/',
        #     include_patterns=['*.txt', '*.jpg'],
        #     exclude_patterns=['*.tmp']
        # )
        # print(f"ç›®å½•ä¸Šä¼ ç»“æœ: {result}")
        
        # ç¤ºä¾‹ 4: è·å–æ–‡ä»¶ URL
        print("\n=== è·å–æ–‡ä»¶ URL ===")
        url = uploader.get_file_url('uploads/puppies.mp4', expires_in=7200)
        print(f"æ–‡ä»¶ URL: {url}")
        
        # ç¤ºä¾‹ 5: åˆ—å‡ºæ–‡ä»¶
        print("\n=== åˆ—å‡ºæ–‡ä»¶ ===")
        files = uploader.list_files('uploads/', max_keys=10)
        for file_info in files:
            print(f"æ–‡ä»¶: {file_info['key']}, å¤§å°: {file_info['size']} bytes")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")




if __name__ == "__main__":
    main()

